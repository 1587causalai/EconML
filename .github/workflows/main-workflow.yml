name: GitHub Actions Test
on: [push]
jobs:
  eval_changes:
    runs-on: ubuntu-latest  
    name: Test changed-files
    outputs:
      code_changes: ${{ steps.check_changes.outputs.code_changes }}
      doc_changes: ${{ steps.check_changes.outputs.doc_changes }}
      nb_changes: ${{ steps.check_changes.outputs.nb_changes }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          fetch-depth: 2

      - id: check_changes
        run: |
          echo "=============== list modified files ==============="
          editedFiles=`git diff --name-only HEAD^ --name-only`
          echo "$editedFiles"

          echo "========== check paths of modified files =========="
          codeChanges=false
          docChanges=false
          nbChanges=false
          for file in "$editedFiles"; do
            echo $file
            case $file in 
            README.md) continue ;;
            econml/_version.py) continue ;;
            prototypes/*) continue ;;
            images/*) continue ;;
            doc/*) docChanges=true ;;
            notebooks/*)  nbChanges=true ;;
            *) codeChanges=true ;;
            esac
          done 

          echo "========== Change Summary =========="
          echo "Code Changes"
          if $codeChanges; then 
            echo "True" 
          else 
            echo "False" 
          fi
          echo "Doc Changes"
          if $docChanges; then 
            echo "True" 
          else 
            echo "False" 
          fi
          echo "Notebook Changes"
          if $nbChanges; then 
            echo "True" 
          else 
            echo "False" 
          fi

          echo "::set-output name=code_changes::$codeChanges"
          echo "::set-output name=doc_changes::$docChanges"
          echo "::set-output name=nb_changes::$nbChanges"
  
  linting: 
    name: Linting
    runs-on: ubuntu-18.04
    needs: eval_changes
    if: ${{ needs.eval_changes.outputs.code_changes }}
    steps: 
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install and Run pycodestyle
        run: pip install pycodestyle && pycodestyle econml
        
  build_documentation:
    name: Build Documentation
    runs-on: ubuntu-18.04
    needs: eval_changes
    if: ${{ needs.eval_changes.outputs.doc_changes }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.6
      - name: Upgrade pip and setuptools
        run: python -m pip install --upgrade pip && pip install --upgrade setuptools wheel Cython
      - name: Install EconML
        run: pip install -e .[all]
      - name: Install graphviz
        run: sudo apt-get -yq install graphviz
      - name: Install lightning
        run: pip install sklearn-contrib-lightning
      - name: Install specific version of shap
        run: pip install git+https://github.com/slundberg/shap.git@d1d2700acc0259f211934373826d5ff71ad514de
      - name: Install sphinx
        run: pip install sphinx sphinx_rtd_theme
      - name: Build documentation
        run: python setup.py build_sphinx -W
      - name: Publish documentation as an artifact
        uses: actions/upload-artifact@v1
        with:
          name: Documentation
          path: build/sphinx/html
      - name: Run doctests
        run: python setup.py build_sphinx -b doctest

  customer_notebooks:
    name: Customer Notebooks
    runs-on: ubuntu-18.04
    needs: eval_changes
    if: ${{ needs.eval_changes.outputs.nb_changes }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install EconML
        run: pip install -e.[tf,plt]
      # Work around https://github.com/pypa/pip/issues/9542
      - name: Upgrade numpy
        run: pip install -U numpy~=1.21.0
      - name: Install Test Dependencies
        run: pip install pytest pytest-runner
      - name: Install Jupyter
        run: pip install jupyter jupyter-client
      - name: Install nb
        run: pip install nbconvert nbformat 
      - name: Install misc.   
        run: pip install seaborn xgboost tqdm
      - name: Unit Tests
        run: python setup.py pytest
        env: 
          PYTEST_ADDOPT: '-m "notebook"'
          NOTEBOOK_DIR_PATTERN: 'CustomerScenarios'
  
  noncustomer_notebooks:
    name: Notebooks (except Customer Solutions)
    runs-on: ubuntu-18.04
    needs: eval_changes
    if: ${{ needs.eval_changes.outputs.nb_changes }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install EconML
        run: pip install -e.[tf,plt]
      # Work around https://github.com/pypa/pip/issues/9542
      - name: Upgrade numpy
        run: pip install -U numpy~=1.21.0
      # shap 0.39 and sklearn 1.0 interact badly in these notebooks
      # shap 0.40 has a bug in waterfall (https://github.com/slundberg/shap/issues/2283) that breaks our main tests
      # but fixes the interaction here...
      - name: Upgrade shap
        run: pip install -U shap~=0.40.0
      - name: Install test dependencies
        run: pip install pytest pytest-runner jupyter jupyter-client nbconvert nbformat seaborn xgboost tqdm
      - name: Unit Tests
        run: python setup.py pytest
        env: 
          PYTEST_ADDOPT: '-m "notebook"'
          NOTEBOOK_DIR_PATTERN: '(?!CustomerScenarios)'
  
  unit_tests:
    strategy:
      fail-fast: false
      matrix:
        python: [3.7, 3.8, 3.9]
        image: [ubuntu-18.04, macOS-10.15, windows-2019]
        type: [main, dml, causal]
    name: Tests ${{ matrix.type }} - Python ${{ matrix.python }} - ${{ matrix.image }}
    runs-on: ${{ matrix.image }}
    needs: eval_changes
    if: ${{ needs.eval_changes.outputs.code_changes }}
    steps:
      # Checkout EconML code
      - name: Checkout code
        uses: actions/checkout@v2
      
      # Setup Python (including pip)
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python }}

      # Upgrade pip and ...
      - name: Upgrade pip and setuptools
        run: python -m pip install --upgrade pip && pip install --upgrade setuptools wheel Cython

      # Enable long path support on Windows so that all packages can be installed correctly
      - name: Enable long paths on Windows
        if: ${{ matrix.image == 'windows-2019' }}
        run: reg add HKLM\SYSTEM\CurrentControlSet\Control\FileSystem /v LongPathsEnabled /t REG_DWORD /d 1 /f
        
      # Install graphviz programmatically on Linux
      - name: Install graphviz on Linux
        if: ${{ matrix.image == 'ubuntu-18.04' }}
        run: sudo apt-get -yq install graphviz
        
      # Install OpenMP on Mac to support lightgbm
      - name: Install OpenML on Mac
        if: ${{ matrix.image == 'macOS-10.15' }}
        run: brew install libomp
        
      # Install EconML package
      - name: Install EconML
        run: pip install -e .[tf,plt]

      # Install test dependencies
      - name: Install Dependencies
        run: pip install pytest pytest-runner

      # Run main unit tests
      - name: Run Unit Tests
        if: ${{ matrix.type == 'main' }}
        run: python setup.py pytest
        env:
          PYTEST_ADDOPTS: '-m "not (notebook or automl or dml or causal)" -n 2'
          COVERAGE_PROCESS_START: 'setup.cfg'

      # Run dml tests
      - name: Run Unit Tests
        if: ${{ matrix.type == 'dml' }}
        run: python setup.py pytest
        env:
          PYTEST_ADDOPTS: '-m "dml"'
          COVERAGE_PROCESS_START: 'setup.cfg'

      # Run tests
      - name: Run Unit Tests
        if: ${{ matrix.type == 'causal' }}
        run: python setup.py pytest
        env:
          PYTEST_ADDOPTS: '-m "causal" -n 1'
          COVERAGE_PROCESS_START: 'setup.cfg'
      
      # Publish test results
      - uses: actions/upload-artifact@v2
        with:
          name: Python ${{ matrix.python }}, ${{ matrix.image }}
          path: junit/test-results.xml

      # Persist coverage data as artifact
      - name: Archive code coverage results
        uses: actions/upload-artifact@v2
        with:
          name: code-coverage-report
          path: output/test/code-coverage.html